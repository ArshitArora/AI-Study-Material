#### Exercise: Handling imbalanced data in machine learning

1. Use [this notebook](https://github.com/codebasics/py/blob/master/DeepLearningML/13_imbalanced/handling_imbalanced_data.ipynb) but handle imbalanced data using simple logistic regression from skelarn library. The original notebook using neural network but you need to use sklearn logistic regression or any other classification model and improve the f1-score of minority class using,
    1. Undersampling
    1. Oversampling: duplicate copy
    1. OVersampling: SMOT
    1. Ensemble

    [Solution](https://github.com/codebasics/py/blob/master/DeepLearningML/14_imbalanced/handling_imbalanced_data_exercise_solution_telecom_churn.ipynb)    
   
2. Take this dataset for bank customer churn prediction : https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling
    1. Build a deep learning model to predict churn rate at bank
    1. Once model is built, print classification report and analyze precision, recall and f1-score
    1. Improve f1 score in minority class using various techniques such as undersampling, oversampling, ensemble etc
    
**I don't have solution link for (2). I might add it in future but for now you try it out on our own. If you have a solution please give me a pull request    
     
